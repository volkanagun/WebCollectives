Index: README.md
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/README.md b/README.md
new file mode 100644
--- /dev/null	(date 1693413453224)
+++ b/README.md	(date 1693413453224)
@@ -0,0 +1,262 @@
+# WebCollectives
+
+WebCollectives is a web content extraction and crawler libray focused on simplicity and ease of use. The majority of the code is compatible to Java 11 syntax. Only, the JSONLookup is written in Scala.
+
+The crawler is integrated into the content extraction process. The user specify the rules to extract the links and later the rule templates are used to
+extract structured XML document from the HTML content without using DOM. Each domain has its own set of rules. These rules can be extracted
+through HTML analysis. In terms of simlicity, the tool uses file system for storing the contents, and 
+it can not be compared with large scale models such as Nutch, Lucene or Solr. In general, the WebCollectives library is a data gathering approach for different tools. It depends on Scala 2.11, Apache FluentHC, HTTPClient, Lucene and JSON4s libraries.   
+
+# Directory Structure
+
+The base and core libraries are located in web folder.
+
+- data
+  - crawler
+    -web
+
+The examples are located at sites folder (i.e. link: [examples](src/data/crawler/sites/)). Each example contains a main method and runs separetely. 
+
+- data
+  -crawler
+    -sites
+
+Other than codes a resources folder (i.e. link: [resources](resources/)) is required to run the program. The required folders in resources folder are as follows.
+
+- resources
+  - selenium
+  - htmls
+
+Selenium is not required for all examples. But some examples traverse the web domain through javascript calls. These repeated calls are necessary in 
+navigating through pages and finding the necessary HTML content. Selenium must be compatible to either chrome or firefox depends on these example. It sets  firefox by doFirefox(true) method in some examples otherwise the Chrome compatible version is called. 
+
+
+# Quick Examples
+
+WebTemplate sets the content directory, seeds and the domain. Seets are the url links for downloading html content. The seeds can be generated from a baseline seed by setPageSuffix method. This method adds new urls through generating the main seed in a predefined boundary.
+
+```java
+WebTemplate template = new WebTemplate("resources/blogs/", "blog-links", "mashable.com");
+template.addSeed("https://mashable.com/review");
+template.setNextPageSuffix("?page=");
+template.setNextPageStart(3);
+template.setNextPageSize(2);
+```
+
+In the above examples, the following urls are generated and traversed by the template
+- https://mashable.com/review?page=3
+- https://mashable.com/review?page=4
+
+Each template contains a regex tree pattern. The regex tree pattern extracts and labels all the sub-patterns that it contains. The subpatterns are defined as a tree structure and should not contain recursions. 
+
+```java
+LookupPattern linkPattern = new LookupPattern(LookupOptions.URL, LookupOptions.CONTAINER, 
+                                                                 "<div class=\"justify-center(.*?)>","</div>")
+                  .setStartEndMarker("<div","</div>")
+                  .add(new LookupPattern(LookupOptions.URL, LookupOptions.ARTICLELINK, 
+                                                            "<a class="block(.*?)href=\"","\""));
+
+template.setMainPattern(linkPattern);
+```
+In the above code block, each pattern states the starting and ending boundaries. In this respect, the pattern given above has the `<div` start marker. The pattern captures the first starting point of the <div class=justify-center block and inside the element it searchers all the `<a class=block` patterns. The text content of this block contains all the links.     
+
+Each template can be linked by addNext method. This method must state the label that holds the links to be followed by the next template.
+
+```java
+template.addNext(articleTemplate, LookupOptions.ARTICLELINK);
+
+```
+In the above code block addNext methods forwards the extracted template content which is labelled by the ARTICLELINK String to the articleTemplate. All the links are downleded and the HTML content is forwarded to the articleTemplate. The lookup pattern of the articleTemplate is used to extract the new content.
+
+In the final stage, a WebFlow object is generated and executed by defining the starting template.
+
+```java
+WebFlow webFlow = new WebFlow(template);
+webFlow.execute();
+```
+
+# Properties of WebTemplate
+
+WebTemplate is responsible from traversing/crawling the links and applying the regex tree to the HTML. In order to control the crawling process thread size, sleeping time in between url requests, radomly selecting the subset of links from the generated urls can be controlled.
+
+```java
+//Creates an instance of the WebTemplate: sets the directory, prefix of downloaded content, and the web domain url.
+WebTemplate template = new WebTemplate(LookupOptions.ARTICLEDIRECTORY, "article-text", "mashable.com");
+//Thread size: the number of threads to download the generated urls.
+template.setThreadSize(3); 
+//Sleep time in milliseconds between each content download.
+template.setSleepTime(1000L);
+//The url request will be made in parallel.
+template.setDoFast(true);
+//It overrides the previously downloaded content. 
+//If it is false, then the downloaded content would not be requested or downloaded again. 
+template.setForceWrite(true);
+//Random count to download from generated urls.
+//In this case 100 web request will be made even though 
+//the number of generated content is larger than this number. 
+template.setDoRandomSeed(100);
+```
+
+# Properties of URL Generators
+WebSuffixGenerator is the main class that is responsible from generating formatted URL strings. These URL are later converted to  WebSeed and can be traced according to the domain. There are several WebSuffixGenerators.
+
+```java
+//Generates date patterns incremented by the day of the year and represented by miliseconds after the suffix (i.e. ?startDate=).
+WebSuffixGenerator generator1 = new WebDayGenerator("?startTime=",startDate, endDate);
+//Generates date patterns incremented by the day of the year and represented based on the defined formatted text.
+WebSuffixGenerator generator2 = new WebDateGenerator("yyyy-MM-dd", startDate, endDate);
+//Page count generator which generates 10 URL strings (i.e. http://skynews.com?Page=10, http://skynews.com?Page=11, ...)
+WebSuffixGenerator generator3 = new WebCountGenerator(10, 20, "?Page="); 
+WebSuffixGenerator generator4 = new WebCountGenerator(5, 10, "&Category=");
+//Multiple suffix generators can be combined based on the defined order.
+List<WebSuffixGenerator> suffixGenerators = new ArrayList<>();
+suffixGenerators.add(generator3);
+suffixGenerators.add(generator4);
+//Generators URL strings based on the ordered combinations: (i.e. http://skynews.com?Page=10&Category=5, http://skynews.com?Page=10&Category=6,...) 
+WebSuffixGenerator multiGenerator = new WebMultiSuffixGenerator(suffixGenerators);
+
+WebTemplate exampleTemplate = new WebTemplate("resources/sky-news/", "skynews-links", "skynews.com");
+exampleTemplate.setSuffixGenerator(multiGenerator);
+
+```
+
+# Crawling the Links of the Target Content 
+
+Generally a Web page contains a relevant content. This content is extracted by LookupPattern and with the extraction the crawling process finishes. For example, a link pattern is first extracts the links, and the links are followed as given in the following example.
+
+```java
+LookupPattern linkPattern = new LookupPattern(LookupOptions.URL, LookupOptions.MAINPAGE, "<div class=\"row\"(.*?)>", "</div>")
+                .setStartEndMarker("<div", "</div>")
+                .addPattern(new LookupPattern(LookupOptions.URL, LookupOptions.ARTICLELINK, "<a href=\"", "\""));
+
+WebTemplate linkTemplate = new WebTemplate(LookupOptions.HURRIYETDIRECTORY, "article-links", domain)
+                .addSeed("economy", "http://www.hurriyet.com.tr/ekonomi/")
+                //If a links ends with a ; reject this link.
+                .setLinkPattern("(.*)","(.*?);")
+                .setDoFast(false)
+                //Do not delete the previously downloaded results
+                .setDoDeleteStart(false)
+                .setSleepTime(1000L)
+                .setDoRandomSeed(randomCount)
+                .setThreadSize(1)
+                .setDomain(domain)
+                .setMainPattern(linkPattern);
+
+```
+In this example the links inside the div HTML element of `<div class="row">` are extracted. All the links except the one ends with semi colon (;) are accepted and used to be followed. To follow these links the article templete is defined and added to the next element of the linkTemplate.
+  
+```java
+  WebTemplate articleTemplate = new WebTemplate(LookupOptions.HURRIYETDIRECTORY, "article-text", domain)
+                .setType(LookupOptions.ARTICLEDOC)
+                //Extract and save this content
+                .setMainContent(true)
+                //All the defined LookupPatterns must exists in the extracted text
+                .setLookComplete(true)
+                .setDoDeleteStart(false)
+                .setThreadSize(1)
+                .setDoFast(false)
+                //Wait between each HTTP request
+                .setSleepTime(1000L)
+                .setDomain(domain)
+                //Download random urls from all the set
+                .setDoRandomSeed(randomCount)
+                .setHtmlSaveFolder(LookupOptions.HTMLDIRECTORY)
+                .setMainPattern(articleLookup)
+                .setForceWrite(true);
+  
+  //apply the article template to extract the content from the downloaded and extracted links of the linkTemplate
+  linkTemplate.addNext(articleTemplate, LookupOptions.ARTICLELINK);
+  
+```  
+
+  Sometimes the main content can have also links to be extracted and used for crawling. In such cases, the following definition must be used.
+  
+  ```java
+   articleTemplate.addExtraTemplate(linkTemplate, LookupOptions.ARTICLELINK);
+  ```
+ In this example, the values of the LookupResult having ARTICLELINK label extracted by the linkTemplate is used to crawl the links in the main article content. This approach creates an inifinite loop. It only finishes when there aren't any new urls left in the main article content.
+ 
+ # Skip and Value Types
+ 
+ Sometimes the defined LookupPattern for extracting the content may not be useful for the output. In such cases, the SKIP type is used in the type definition of the LookupPattern. An example is given as follows.
+ 
+ ```java
+        LookupPattern articleLookup = new LookupPattern(LookupOptions.ARTICLE, LookupOptions.CONTAINER, "<div class=\"container\">", "</div>")
+                .setStartEndMarker("<div", "</div>")
+                .setNth(0)
+                .addPattern(new LookupPattern(LookupOptions.TEXT, LookupOptions.AUTHOR, "<div class=\"news-profile\">", "</div>")
+                        .setStartEndMarker("<div","/div")
+                        .setNth(0)
+                        .setRemoveTags(true))
+                .addPattern(new LookupPattern(LookupOptions.SKIP, LookupOptions.CONTAINER, "<span class=\"news-date\">", "</span>")
+                        .setNth(0)
+                        .setRemoveTags(true))
+                .addPattern(new LookupPattern(LookupOptions.TEXT, LookupOptions.ARTICLETITLE, "<h1(.*?)>", "</h1>")
+                        .setNth(0)
+                        .setRemoveTags(true))
+                .addPattern(new LookupPattern(LookupOptions.ARTICLE, LookupOptions.ARTICLETEXT, "<div class=\"news-content(.*?)>", "</div>")
+                        .setStartEndMarker("<div", "</div>").setNth(0)
+                        .addPattern(new LookupPattern(LookupOptions.ARTICLE, LookupOptions.ARTICLEPARAGRAPH, "<(p|h2(.*?))>", "</(p|h2)>")))
+                .addPattern(new LookupPattern(LookupOptions.SKIP, LookupOptions.CONTAINER, "<div class=\"news-tags\">", "</div>").setNth(0)
+                        .addPattern(new LookupPattern(LookupOptions.TEXT, LookupOptions.GENRE, "NEWS")
+                                        .setNth(0)
+                                        .setRemoveTags(true)));
+ ```
+ 
+ The output of the above definition is given in XML.
+ 
+ ```xml
+<ROOT LABEL="ARTICLE-DOC">
+<RESULT TYPE="ARTICLE" LABEL="CONTAINER">
+<RESULT TYPE="TEXT" LABEL="AUTHOR">
+....
+</RESULT>
+<RESULT TYPE="TEXT" LABEL="DATE">
+....
+</RESULT>
+<RESULT TYPE="TEXT" LABEL="ARTICLETITLE">
+....
+</RESULT>
+<RESULT TYPE="ARTICLE" LABEL="ARTICLETEXT">
+<RESULT TYPE="ARTICLE" LABEL="ARTICLEPARAGRAPH">
+....
+</RESULT>
+<RESULT TYPE="ARTICLE" LABEL="ARTICLEPARAGRAPH">
+....
+</RESULT>
+</RESULT>
+
+<RESULT TYPE="TEXT" LABEL="GENRE">
+NEWS
+</RESULT>
+</RESULT>
+</ROOT>
+
+```
+
+The SKIP LookupPatterns are not placed in the output XML file. On the other hand, a static value is defined in the output for the GENRE LookupPattern.  
+ 
+ # Issues and Answers
+ 
+ ####
+ 1. The lookup pattern does not find any links in the given url seeds!
+
+  One of the reason why the defined patterns do not match anything is that the content of the Web page displayed in the browser is different from the downloaded content in the program. Unfortunately this happens in some of the Web sites, because dynamic content generation may change the HTML elements according to the browser.
+ 
+ 2. The LookupPattern do not retrieve correct content defined by start and end regular expressions!
+
+To be able to retrieve the correct boundary, lookup pattern uses a stack based parsing approach. When there are multiple matching HTML tags such as <div elements, they must be defined by `.setStartEndMarker("<div","/div")` so that the parser knows which tags are repeating.
+
+ 3. The program downloads links but it is not saving them to disk.
+
+The LookupPattern may not extract all the defined content. This may be because of the design changes in pages. In order to save the results partially to disk `setLookComplete(false)` must be set. In cases where all the content is necessary for saving the content then `setLookComplete(true)` must be set.
+
+
+ 
+
+
+
+
+    
+
+
Index: .idea/codeStyles/Project.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/codeStyles/Project.xml b/.idea/codeStyles/Project.xml
new file mode 100644
--- /dev/null	(date 1693422001208)
+++ b/.idea/codeStyles/Project.xml	(date 1693422001208)
@@ -0,0 +1,7 @@
+<component name="ProjectCodeStyleConfiguration">
+  <code_scheme name="Project" version="173">
+    <ScalaCodeStyleSettings>
+      <option name="MULTILINE_STRING_CLOSING_QUOTES_ON_NEW_LINE" value="true" />
+    </ScalaCodeStyleSettings>
+  </code_scheme>
+</component>
\ No newline at end of file
Index: LICENSE
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/LICENSE b/LICENSE
new file mode 100644
--- /dev/null	(date 1693413453220)
+++ b/LICENSE	(date 1693413453220)
@@ -0,0 +1,21 @@
+MIT License
+
+Copyright (c) 2023 volkanagun
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
